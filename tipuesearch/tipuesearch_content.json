{"pages":[{"title":"Hadoop - Big Data's Best Friend","url":"/2017/08/23/hadoop-big-data-best-friend/","text":"What is Hadoop?Hadoop is a framework of MapReduce utilized for handling “Big Data” operations and storage. MapReduce is a programming model utilized for handling database clusters (separate computers that work in unison with one another for a central task) Hadoop is broken up into four main components: Hadoop Common (standard library for Hadoop) HDFS (Hadoop Distributed File System) MapReduce Engine (JobTracker &amp; TaskTracker) YARN (Yet Another Resource Negotiator) Hadoop CommonHadoop Common is the standard library for Hadoop. Previously titled “Hadoop Core”, the name was changed to “Hadoop Common” in July 2009. The name was changed because it’s the list of common libraries and utilities used by Hadoop. Not the most exciting reasons for the name change. Hadoop Common also includes the necessary Java Archive (.jar) files that Hadoop needs to work with the Java Virtual Machine. Hadoop Common also includes several codecs utilized for compression (e.g. bzip2). For a full overview of Hadoop Common, see this mirror from Github: https://github.com/apache/hadoop-common Hadoop’s Distributed File System (HDFS) NameNode is a special server for storing metadata on files. Files themselves stored in DataNode. NameNode also contains maps to direct metadata from each file to an appropriate data block in the DataNode servers. Each cluster in Hadoop has its own NameNode with the current build of Hadoop. Secondary NameNode acts as a helper to create checkpoints (keeps track of what data has been read, modified, etc) for NameNode. It is NOT a backup. However Secondary NameNode is used for protection from corruption in the event that [first] NameNode is ever dropped. Actual backups must be handled by the database administrator(s) themselves instead of being built into Hadoop. MapReduce Engine - JobTracker &amp; TaskTrackerJobTracker (JT) JT takes in tasks from client, then delegates information out to a corresponding TaskTracker service workers. JT also monitors status of jobs from corresponding TT service workers, then transmits status to the client. If the JT of a NameNode goes down, HDFS will still be able to work but MapReduce executions will be stopped and halted. No further MapReduce executions will be able to be sent to JobTracker to delegate to TaskTracker service workers. TaskTracker (TT) Built to handle Mapper and Reducer jobs delegated by the JobTracker that summoned it. Maps are just key-value pairs of transformed data. E.g. [1,2,3,4] mapped with * 2 = [2,4,6,8]; Reducers are transformations of records with similar keys down into a smaller set. TaskTrackers are slaves to their summoning JT. In the event a TT goes down, JT will simply reassign the task to a new TaskTracker. TaskTracker Overview of MapReduce call chain The example above is a diagram of how a word count program in Hadoop which map words in a file together (finding all instances of the word) and then reduces the amount of found words into a single value (the actual number of times the word appears in the file). Found at: https://examples.javacodegeeks.com/enterprise-java/apache-hadoop/hadoop-hello-world-example/ YARN (Yet Another Resource Negotiator)Used to decouple resource management from actual MapReduce jobs. YARN works by using a central Resource Manager that contacts individual “Node Managers” that exist on each separate machine in the cluster (the “nodes” of the cluster). Node Managers manages containers on each node. Application Master (App Mstr) is used to communicate information about resources between the Resource Manager and individual Node Managers. The Resource Manager also utilizes a Scheduler to schedule requests with individual Node Managers through the App Master. Note that the Scheduler does not deal with fault tolerance. It merely keeps track of resources. Fault tolerance is instead handled via the individual Node Manager of each machine. Fault tolerance is also handled by particular Hadoop frameworks (e.g. HortonWorks). Data Replication also used for fault tolerance. Fault Tolerance / Hadoop HANameNode serves as single point of failure for Hadoop. If NameNode drops, cluster access becomes unavailable. Hadoop High Availability aims to relieve NameNode as SPOF via Quorum Journal Manager (QJM). Second NameNode used as slave to first NameNode in a “standby mode” via “JournalNodes” (JNs); JNs are used to correspond client operations. To avoid possible data corruption, HA cluster enforces only allow a single active NameNode to be the “writer” to JournalNodes. Data corruption can arise from “split-brain scenario” (nodes in cluster believe they are the only active node). Hadoop Streaming – Performance &amp; OverheadHadoop natively works utilizing Java but offers support to work with other languages (e.g. Python, Ruby, etc) via Hadoop Streaming. Hadoop Streaming provides more abstract implementation of Hadoop for generating jobs for Hadoop, there is a performance overhead that makes Hadoop Streaming a more costly implementation over using Java. Overhead bottleneck comes from implementation of Linux pipe feature. Linux pipe() system call is half-duplex, so two pipes must be opened to read and write data between Hadoop filesystem and external executable file. Java I/O operations rewrite map pairs to external executables which in turn leads to a performance overhead. (Zheng et. al). Breakdown of Hadoop Streaming Overhead Security: HDFS’s VulnerabilitiesHDFS supports no authentication model in its raw form. Instead relies upon Unix-level authentication &amp; authorization. As such, HDFS is open to several types of attacks, ranging from impersonation, cluster head bypass attacks, and eavesdropping attacks. No encryption of sensitive data in HDFS’s vanilla state. “Heavy weight cryptographic operations” are left out due to high overhead on performance. Security measures are dependent upon company policy and use of security systems such as Kerberos. Sources – Online Information👉 What is Hadoop? - Wikipedia 👉 HDFS 👉 HDFS Checkpoints 👉 Secondary NameNode 👉 Hadoop Common - Github 👉 MapReduce Engine’s Processes 👉 YARN - Hadoop Docs 👉 HDFS with QJM - Hadoop Docs 👉 Security Sources – Papers[1] Fault Tolerance / Hadoop HA - Wang, F., Qiu, J., Yang, J., Dong, B., Li, X., &amp; Li, Y. (2009). Hadoop high availability through metadata replication. Proceeding of the first international workshop on Cloud data management - CloudDB 09. doi:10.1145/1651263.1651271 [2] Hadoop Security &amp; Vulnerabilities - Sarvabhatla, M., Reddy, M. C., &amp; Vorugunti, C. S. (2015). A Robust and Light Weight Authentication Framework for Hadoop File System in Cloud Computing Environment. Proceedings of the Third International Symposium on Women in Computing and Informatics - WCI 15, 463-468. doi:10.1145/2791405.2791410 [3] Hadoop Streaming - Ding, M., Zheng, L., Lu, Y., Li, L., Guo, S., &amp; Guo, M. (2011). More Convenient More Overhead: The Performance Evaluation of Hadoop Streaming. Proceedings of the 2011 ACM Symposium on Research in Applied Computation - RACS 11, 307-313. doi:10.1145/2103380.2103444 Sources - Images👉 Hadoop Logo 👉 HDFS Overview 👉 TaskTracker Overview 👉 YARN Architecture 👉 QJM Overview","tags":"hadoop big-data hdfs mapreduce distributed-systems distributed-file-system"},{"title":"Introduction to Torrenting & Torrent Clients​","url":"/2017/08/23/introduction-to-torrenting-and-torrent-clients​/","text":"What is a torrent client?​A tool that helps assist users in downloading files seamlessly, quickly, and without depending upon a centralized server.​ Implements the BitTorrent protocol. Why use torrenting? We’ll explore this next.​ Torrenting: Terminologies &amp; Why Torrent?​Torrents are files that point to a remote server or themselves act as the server. This server contains a list of machines that contain portions of the file(s) to download. Machines that are downloading a file are known as “peers”.​ Machines that contain even just a portion of a file AND are able to share the file are known as “seeds”. ​ When multiple machines all are sharing the same torrent file, this is known as a “swarm”.​ Torrenting is much faster than utilizing a centralized server for two main reasons:​ High levels of traffic to a machine can slow down the machine or cause a crash from servicing too many requests at once.​ BitTorrent protocol allows seeds themselves to immediately start sharing information once portions of a file have been downloaded. Another machine does not need to wait for the first machine to finish downloading the file before it can receive parts of the file.​ Illustration of a typical BitTorrent Swarm​ Managing Torrents​The decentralized nature of torrenting is great in theory but for it to work in practice, we’d still need some way of keeping track of all the machines downloading a file (peers) and all the machines that are acting as a container for a file (seeds).​ BitTorrent handles this via a “Tracker”. The tracker keeps track of all peers connected in a swarm along with all of the various seeds that peers can connect to, to access a file.​ The tracker also keeps track of what “part” of a file is attached to what machine. This ensures that peers will get the various pieces of data that they need for a file and no duplicate copies of information that has already been attained.​ BitTorrent Tracker Diagram​ BitTorrent Vulnerabilities : Loss of Seed​BitTorrent’s use of swarms &amp; multiple seeds for components of a file allows peers to potentially download files faster. Part of this is by allowing machines with only a portion of a file to immediately begin transferring data. But what happens if a seed exits a swarm? Do we lose a vital chunk of data?​ No! BitTorrent works around this by way of “rarest first” algorithm. What is the “rarest first” algorithm?​ Each piece of data in a file is assigned a value. Each peer in a swarm has attached with it a reference to those pieces of data. When a new peer joins the swarm, the BitTorrent protocol will look for the data with the lowest reference count (therefore the rarest piece) and will give any and all new peers that section of data before any “common” pieces of information.​ Now if a seed in the BitTorrent swarm goes away (e.g. disconnect), chances are higher that all other peers will have any pieces of data that the lost seed contained.​ BitTorrent Vulnerabilities: Multiple Requests​Rarest-first algorithm helps us circumvent the issue of data loss from a seed being removed from a swarm but another pitfall is the bottleneck imposed on each seed of the swarm.​ When a peer requests a portion of a file from a seed, the seed must spend some time accessing the component of the file and stream it to the peer. ​ When too many requests are made to a seed at once, the seed may refuse to communicate with a peer. This is known as “choking”.​ To work around choking, BitTorrent will rotate which seed should be targeted by a peer via a “choking algorithm”. Likewise, to “unchoke” a seed, the server will send an unchoke message to tell it to stop blocking requests from peers that may be targeting the seed.​ BitTorrent Vulnerabilities: Ambiguous Speeds​All seeds are peers but not all peers are seeds. When a peer is a member of a swarm and downloads a file but does not act as a seed, this peer is known as a &quot;leech&quot;.​ High prevalence of &quot;leechers&quot; will impose a lot of stress on the number of requests given to a seed while at the same time not increasing file transfer performance. Controlling the amount of leechers could block out some potential users and/or add in extra overhead.​ The exact number of peers for any given swarm and any given file is heavily dependent both on the popularity of a file (more downloaded files will have more seeds, therefore higher download speeds for new peers) and on the number of seeds attached to a given swarm.​ Because of this, the exact speeds of any given swarm are speculative at best. For business class software, this kind of ambiguous speeds could result in the software failing to achieve popularity on the market. ​ Ancillary Challenges: No search engine!​One problem posed with torrent clients is the lack of a search engine built in. When a peer intends to torrent a file, the user of the peer must know exactly what they are looking for and where to look for it. Torrent search engines do exist as third parties but are not built into the box. ​ Utilization of these third parties also pose problems both due to the fact that at times torrents are used to transfer illegal content (e.g. copyrighted materials) and due to that fact, at times these torrent search engines will contain malicious software (malware).​ At times the validity of a particular torrent can be suspect as well. Torrent files themselves (especially if in a compressed format such as .zip) can at times contain malware. This makes at least some torrent search engines even harder to trust.​ Sources Used &amp; Useful Links🍕 Rarest First Principle - PDF 🌭 Vaibhav Walia - Github 🍔 BitTorrent Protocol - Github 🍟 Create Torrent - Github 🌮 WebTorrent CLI - Github ​ 🌯 Node.js 🍜 npm 🍮 Internet Archive 🍭 Vuze - Legal Torrents 🍺 ASCII Art Generator ​","tags":"distributed-systems en-🇺🇸 school🎓 torrent file-system peer-to-peer"},{"title":"春花秋月何时了，往事知多少。","url":"/2017/08/15/hello-world/","text":"我叫王璐瑶，“璐”和“瑶”意美玉，土生土长的北京人，说话有京腔儿，打字爱加儿化音。 初中人大附，高中北师大实验，大学对外经贸（管理学学士学位 : 会计💁），之后保研本校（科学硕士学位 : 会计💁）。 本科我学习努力，一切顺利，拿过国家奖学金，也保了研。研一结束之后我来了美国，进入了加州大学伯克利分校(UC Berkeley 🐻)学电子工程和计算机科学(EECS)。2016年十月加入Cisco，开心的当了半年软件工程实习生😁，浅尝了做一个职业程序媛儿的赶脚🤓， #大数据 #数据库 #人工智能 #机械学习。2017年三月，我接受了加州州立东湾分校(Cal State East Bay)计算机科学硕士项目的录取。 从国内🇨🇳到美国🇺🇸打拼、从会计转行做程序媛、一个硕士重新读大一，个中缘由和滋味、三年的心酸历程、对父母的思念、对国内好朋友们的想念、几次转学、二十次搬家、对转行的怀疑，我的文笔写不出，我也没必要诉苦和矫情。详尽的英文简历看这里🙋。 来贴我的一张图问好！ changelog:","tags":"中文🇨🇳 个人简介"},{"title":"search","url":"/search/index.html","text":"","tags":""},{"title":"Discussion Session Homepage","url":"/cs3240/index.html","text":"CS 3240 Data Structures and Algorithms, Fall 2017Instructor : Hank Stalica Lecture : TuTh 8 - 9:50 PM, Science N104 SI Leader : Lulu Wang Discussion Session (SI Session) : TBA Google form First Discussion Session : Wed Sep 27, 6 - 7 PM, LI 3149 (free snacks!) Contact Lulu: lwang31@horizon.csueastbay.edu 123456 __ __ _ _ _ _/ / /\\ \\ \\___| | ___ ___ _ __ ___ ___ / \\/ \\/ \\\\ \\/ \\/ / _ \\ |/ __/ _ \\| &apos;_ ` _ \\ / _ \\ / / / / \\ /\\ / __/ | (_| (_) | | | | | | __/ /\\_/\\_/\\_/ \\/ \\/ \\___|_|\\___\\___/|_| |_| |_|\\___| \\/ \\/ \\/ Announcements The brief presentation that I gave on the first day of class is posted. First discussion session is tentatively scheduled to be Wednesday of the second week of class (Sep 27, 6 - 7 PM). First Day of Class First Discussion Session : Wed Sep 27, 6 - 7 PM (free snacks!) Hi I’m Looloo. I’ll be your supplemental Instruction (SI) Leader for this quarter. I am a proud member of this great organization called SCAA (Student Center for Academic Achievement). I took CS 3560 Intro to Systems Programming with Professor Stalica last quarter. Professor Stalica is extremely awesome, super chill and helpful. I really look forward to work with him to help you learn and succeed in this course. Professor Stalica is currently working on giving me access to BlackBoard for this course. Once I can access this course on BlackBoard, I will send out Google forms for the meeting time, as well as future logistics informatin via emails to all of you. For now, it is highly adviced that you mark down the URL for this website. Throughout this quarter, I will put up discussion session materials on this page. About myself, I am a graduate student in Computer Science. This is my third quarter here at CSUEB. I took my Data Structures and Algorithms last quarter with Dr. Varick Erickson. If you would like to know more about me, feel free to click on the About tab. This is my personal blog that is not yet populated. Data Structures and Algorithms is an extremely important course for CS majors because the knowledge and skills that you gain from this course will be applicable throughout your career course. I will be hosting discussion session twice a week (one discussion session per lecture). Around Midterm and Final, I will also be hosting extra review sessions to help you prepare for the exams. For more information, please come to the first meeting next Wednesday. I will be covering logistics, review or preview of the first lecture, LeetCode fun problems and more! ResourcesProfessor Hank Stalica’s Youtube LeetCode LeetCode Solutions by Salty Egg Textbook : Algorithms, 4th Edition by Robert Sedgewick and Kevin Wayne Berkeley Resources Student Center for Academic Achievement (SCAA) Homepage Google Code Jam","tags":""},{"title":"Contact us!","url":"/contact/index.html","text":"If you’d like to contact Luyao “Lulu” Wang, please see my contact information below: Luyao “Lulu” Wang: luyao_wang@berkeley.edu https://github.com/luyao-wang https://www.linkedin.com/in/lulu-wang-903293a4/","tags":""},{"title":"About Looloo","url":"/about/index.html","text":"Hi, I’m Luyao “Lulu” Wang, a student from California State University East Bay. I’m a computer science student, working on my Master’s, to code for a better world and to get experience for myself. If you’d like to contact Luyao “Lulu” Wang, please see my contact information below: luyao_wang@berkeley.edu https://github.com/luyao-wang https://www.linkedin.com/in/lulu-wang-903293a4/ Below you can see my personal resume: 📝 Luyao “Lulu” Wang Resume - PDF WORK EXPERIENCESoftware Engineer Intern - Cisco Systems, Inc. : October 2016 - April 2017 🇺🇸 Database Management, querying, trobleshooting of database. Generation of reports for team members for each weekly meeting. Performance monitoring &amp; analysis of Cisco wireless systems on Cisco’s newest wireless project. Software Engineer Intern - Maru Me : June 2016 - August 2016 🇺🇸 Maintenance &amp; development of Maru Me’s iOS application including: debugging issues of previous versions and UX/UI development. Marketing Intern - Philips : August 2012 - March 2013 🇨🇳 Review of purchase orders for healthcare events, approval of budget plans for Philips’ healthcare marketing department, and data entry of purchase orders. Accounting Intern - PwC (PricewaterhouseCoopers) : July 2012 - August 2012 🇨🇳 Coordination of mid-year auditing projects for PwC’s clients. Tasks included: Bank reconciliation operations, processing of client information for audit reports. Marketing Intern - ING Group : Feburary 2011 🇨🇳🇭🇰 Collection and analysis of customer feedback regarding ING’s insurance products. Creation and delivery of marketing plans. SKILLSProgramming Languages: C, C++, Java, Python, SQL, JavaScript, Swift Natural Languages: English, Mandarin Tools: Git, Xcode, BASH Scripting EDUCATIONMaster of Science – Computer Science : Expected May 2018 🇺🇸 California State University East Bay GPA: 4.00 Master of Science – Accounting : June 2017 🇨🇳 University of International Business and Economics (Beijing) GPA: 3.86 Computer Science : 2014 - 2016 🇺🇸 University of California Berkeley GPA: 3.87 Completed 90 credits towards a Bachelor’s Degree in Computer Science. TUTORINGCALIFORNIA STATE UNIVERSITY EAST BAY 🇺🇸 Student Instructor - SCAA : September 2017 - Present Creation of lesson plans &amp; activities along with tutoring of students for Data Structures &amp; Algorithms course. UNIVERSITY OF INTERNATIONAL BUSINESS AND ECONOMICS (BEIJING) 🇨🇳 Course Assistance : September 2011 - January 2012 Collection and grading of assignments and exams, scheduling office hours for students, and technician of multimedia equipment for instructors. ACADEMIC ACHIEVEMENTS AND AWARDSUIBE BEIJING 🇨🇳 Valedictorian 🎓 : 2013 Dean’s and President’s Lists 💯 : 2009 - 2013 Business School Student Council Representative : 2011 - 2013 PwC Award : 2011 PriceWaterhouseCoopers award granted only to 16 people per year. Recipient also has the eligibility to receive an internship from PriceWaterhouseCoopers, one of the largest account firms in the world. Silver Medal in 200m Freestyle &amp; 200m Breaststroke 🏊‍ : 2011 OTHER 🇺🇸 Chinese American Citizens Alliance Community Service Award : 2016","tags":""},{"title":"tags","url":"/tags/index.html","text":"","tags":""}]}